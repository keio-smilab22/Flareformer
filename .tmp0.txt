==========================================
{'wandb_name': 'id13-4b_2014_with_mae', 'epochs': 40, 'lr': 7e-07, 'bs': 19, 'lambda': {'GMGS': 0.0001, 'BS': 10}, 'save_model_path': 'models/id1-4b.pth', 'dataset': {'window': 4, 'year_split': {'train': {'start': 2010, 'end': 2013}, 'valid': {'start': 2014, 'end': 2014}, 'test': {'start': 2014, 'end': 2014}}, 'mean': 91.0729, 'std': 57.5899, 'GMGS_score_matrix': [[0.32253222, -0.29649121, -0.66356076, -1], [-0.29649121, 0.42576394, 0.05869439, -0.27774485], [-0.66356076, 0.05869439, 3.68555451, 3.34911527], [-1, -0.27774485, 3.34911527, 39.45652268]], 'climatology': [0.9081, 0.0919]}, 'MM': {'N': 1, 'd_model': 128, 'h': 4, 'd_ff': 16, 'dropout': 0.1}, 'SFM': {'N': 1, 'd_model': 128, 'h': 4, 'd_ff': 16, 'dropout': 0.1}, 'input_channel': 90, 'output_channel': 4, 'main_metric': 'GMGS'}
==========================================
data/data_2010_label.csv
data/data_2011_label.csv
data/data_2012_label.csv
data/data_2013_label.csv
data/data_2010_feat.csv
data/data_2011_feat.csv
data/data_2012_feat.csv
data/data_2013_feat.csv
data/data_2010_window_48.csv
data/data_2011_window_48.csv
data/data_2012_window_48.csv
data/data_2013_window_48.csv
img: torch.Size([29247, 1, 256, 256]) label: (29247, 4) feat: (29247, 90) window: (29247, 4)
Calculating std :  0 / 1
Calculating std :  1 / 1
0.35716575 0.22504742444964324
data/data_2014_label.csv
data/data_2014_feat.csv
data/data_2014_window_48.csv
img: torch.Size([8127, 1, 256, 256]) label: (8127, 4) feat: (8127, 90) window: (8127, 4)
data/data_2014_label.csv
data/data_2014_feat.csv
data/data_2014_window_48.csv
img: torch.Size([8127, 1, 256, 256]) label: (8127, 4) feat: (8127, 90) window: (8127, 4)
Batch Sampling
<All keys matched successfully>
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
FlareTransformerWithMAE                  --
├─InformerEncoderLayer: 1-1              --
│    └─AttentionLayer: 2-1               --
│    │    └─ProbAttention: 3-1           --
│    │    └─Linear: 3-2                  65,792
│    │    └─Linear: 3-3                  65,792
│    │    └─Linear: 3-4                  65,792
│    │    └─Linear: 3-5                  65,792
│    └─Conv1d: 2-2                       4,112
│    └─Conv1d: 2-3                       4,352
│    └─LayerNorm: 2-4                    512
│    └─LayerNorm: 2-5                    512
│    └─Dropout: 2-6                      --
├─InformerEncoderLayer: 1-2              --
│    └─AttentionLayer: 2-7               --
│    │    └─ProbAttention: 3-6           --
│    │    └─Linear: 3-7                  65,792
│    │    └─Linear: 3-8                  65,792
│    │    └─Linear: 3-9                  65,792
│    │    └─Linear: 3-10                 65,792
│    └─Conv1d: 2-8                       4,112
│    └─Conv1d: 2-9                       4,352
│    └─LayerNorm: 2-10                   512
│    └─LayerNorm: 2-11                   512
│    └─Dropout: 2-12                     --
├─CNNModel: 1-3                          --
│    └─Conv2d: 2-13                      784
│    └─BatchNorm2d: 2-14                 32
│    └─ReLU: 2-15                        --
│    └─MaxPool2d: 2-16                   --
│    └─Bottleneck: 2-17                  --
│    │    └─Conv2d: 3-11                 128
│    │    └─BatchNorm2d: 3-12            16
│    │    └─Conv2d: 3-13                 576
│    │    └─BatchNorm2d: 3-14            16
│    │    └─Conv2d: 3-15                 256
│    │    └─BatchNorm2d: 3-16            64
│    │    └─ReLU: 3-17                   --
│    │    └─Sequential: 3-18             576
│    └─AdaptiveAvgPool2d: 2-18           --
│    └─Flatten: 2-19                     --
│    └─Softmax: 2-20                     --
│    └─Linear: 2-21                      4,128
│    └─Linear: 2-22                      132
│    └─BatchNorm2d: 2-23                 64
│    └─Dropout: 2-24                     --
├─Linear: 1-4                            2,052
├─Linear: 1-5                            524,544
├─Softmax: 1-6                           --
├─Linear: 1-7                            262,400
├─Linear: 1-8                            262,400
├─ReLU: 1-9                              --
├─Linear: 1-10                           23,296
├─BatchNorm1d: 1-11                      8
=================================================================
Total params: 1,626,784
Trainable params: 1,626,784
Non-trainable params: 0
=================================================================
====== Epoch  0  ======
[[5593  736  758  221]
 [2615 1410 1438 1845]
 [1018  929 1408 3953]
 [ 330  527  484 5967]]
x:  0.5419631454114213
m:  0.5165571975916804
c:  0.5845648604269295
[[1565  278  215  172]
 [1424 1069 1023 1028]
 [ 100  111  244  752]
 [   2    4   10  130]]
x:  0.6458300793150856
m:  0.4797101477738346
c:  0.4430180733381951
Epoch 0: Train loss:7.6758  Valid loss:8.1327 {'valid_ACC': 0.3701242771010213, 'valid_TSS-M': 0.4797101477738346, 'valid_BSS-M': -1.401360144749105, 'valid_GMGS': 0.5228527668090384}
====== Epoch  1  ======
[[6015  996  237   60]
 [1924 2748 1502 1134]
 [ 693 1312 2034 3269]
 [ 114  497  258 6439]]
x:  0.6775223499361431
m:  0.6203475643130816
c:  0.6985039226418537
[[1416  505  176  133]
 [1078 1702 1032  732]
 [  69  192  354  592]
 [   1    5   16  124]]
x:  0.6667564918736794
m:  0.4966377246508595
c:  0.4403023198692654
Epoch 1: Train loss:6.6553  Valid loss:7.7968 {'valid_ACC': 0.4424756982896518, 'valid_TSS-M': 0.4966377246508595, 'valid_BSS-M': -1.2992852803171024, 'valid_GMGS': 0.5345655121312681}
====== Epoch  2  ======
[[5808 1225  228   47]
 [1613 3258 1570  867]
 [ 561 1471 2550 2726]
 [  54  501  290 6463]]
x:  0.7183451924831236
m:  0.6374521072796935
c:  0.6931216931216931
[[1315  633  148  134]
 [ 918 1974  988  664]
 [  60  222  385  540]
 [   1    5   21  119]]
x:  0.6474203287602577
m:  0.5016362942436091
c:  0.4236694800350714
Epoch 2: Train loss:6.3195  Valid loss:7.6564 {'valid_ACC': 0.4667158853205365, 'valid_TSS-M': 0.5016362942436091, 'valid_BSS-M': -1.2848047627617338, 'valid_GMGS': 0.5242420343463127}
====== Epoch  3  ======
[[5765 1268  236   39]
 [1510 3444 1603  751]
 [ 491 1518 2908 2391]
 [  25  452  296 6535]]
x:  0.749133369823025
m:  0.6500410509031198
c:  0.6964513774858603
[[1315  666  137  112]
 [ 896 2123  962  563]
 [  58  261  440  448]
 [   1    6   36  103]]
x:  0.5647702677420519
m:  0.49717028130906155
c:  0.4277393460686478
Epoch 3: Train loss:6.0857  Valid loss:7.4991 {'valid_ACC': 0.4898486526393503, 'valid_TSS-M': 0.49717028130906155, 'valid_BSS-M': -1.1922105743941251, 'valid_GMGS': 0.4965599650399204}
====== Epoch  4  ======
[[5778 1294  204   32]
 [1443 3585 1550  730]
 [ 458 1548 3234 2068]
 [   9  398  282 6619]]
x:  0.776637474913337
m:  0.6627668308702791
c:  0.7035212552453931
[[1254  688  152  136]
 [ 812 2099  976  657]
 [  52  238  430  487]
 [   1    6   34  105]]
x:  0.5587971775432405
m:  0.4969035119934902
c:  0.41564708360487324
Epoch 4: Train loss:5.8827  Valid loss:7.6240 {'valid_ACC': 0.47840531561461797, 'valid_TSS-M': 0.4969035119934902, 'valid_BSS-M': -1.3284404307372568, 'valid_GMGS': 0.49044925771386794}
====== Epoch  5  ======
[[5761 1296  215   36]
 [1384 3640 1577  707]
 [ 416 1522 3521 1849]
 [   1  355  253 6699]]
x:  0.798440065681445
m:  0.6696086480569239
c:  0.7061667578908958
[[1261  667  161  141]
 [ 823 2058 1030  633]
 [  51  232  451  473]
 [   1    6   48   91]]
x:  0.4670415867823067
m:  0.49558177641523576
c:  0.4170903195437978
Epoch 5: Train loss:5.7373  Valid loss:7.6431 {'valid_ACC': 0.4750830564784053, 'valid_TSS-M': 0.49558177641523576, 'valid_BSS-M': -1.3496623998452812, 'valid_GMGS': 0.4599045609137801}
====== Epoch  6  ======
